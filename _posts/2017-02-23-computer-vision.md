---
layout: post
title: Computer Vision
---
*Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that can interface with other thought processes and elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory. (Wikipedia)*

Basically, computer vision involves the use of algorithms to make computers see and understand the world like we do. What do I mean by ‘like we do’? Well, we see and understand the world in terms of colors, edges, depth, orientation, shapes, texture and many other such features (or concepts as you can call it). This process of understanding the visual data happens automatically in the visual cortex of our brains and help us make descriptions of what we see and use that information with other thought processes to make decisions and answer questions like ‘where is my phone?’ or ‘how do I know where to walk without tipping over?’. Our brains have been designed to make this process look like magic.

But when the world is captured as a digital image, it is stored in the computer’s memory as a collection pixel values. The methods of computer vision involves modeling of features (by modeling, I mean developing an algorithm that defines a particular feature in terms of pixel values) and extracting these features to be used by other parts of the system as inputs (or information).

Heres two traditional methods used in computer vision for feature detection:
- **Canny Edge Detection**: Canny edge detection algorithm is used to detect edges in an image. It works on a grayscale image and identifies edges based on the calculated gradient of each of the pixels in the image where gradient is defined as an increase in the magnitude of a property (pixel intensities in this case) observed in passing from one point to another. Usually, the grayscale image is smoothened using a Gaussian blur before the gradients are calculated. Since an image can be described mathematically in the form f(x, y), we can perform mathematical operations on it. To find the gradient of the image, one of the operators we can use is called the Sobel operator (it is just a kernel that gives the strength of the intensity of gradient through its convolution on the image). We apply the Sobel operator on the image along both x and y direction and compute the strength of the gradient. The canny edge detector then thins the edges obtained by the Sobel operator by applying another transformation function called the canny operator that uses something called a [Hysteresis thresholding](https://www.youtube.com/watch?v=sRFM5IEqR2w). The output from canny edge detector is a binary image where we have white thin edges detected while everything else is black (edges are actually white pixel points over a black background).
<div style="text-align:center"><figcaption>Canny edge detection applied to a photograph (Wikipedia)</figcaption><img src="https://thekhblog.wordpress.com/wp-content/uploads/2017/02/canny_edges.png" /></div>

<br/>
- **Hough transform for line detection**: This is a method in computer vision that is used to identify continuous lines from the noisy edge points obtained from an edge detector. Hough transform is a transformation function that converts lines in image space (x vs. y) to points in parameter space also called as Hough space. The axes of the parameter space depend on how a line is defined. The Hough space is (m vs. c) if a line is defined as y = m * x + c in the image space (m is the slope of the line and c is its y-intercept). This line is represented as a point (m, c) in the Hough space. We can also see that a point (x, y) in image space represents a line c = y – m * x in the Hough space. Hence for each point in the image space, we have a line representation in the Hough space.  We can see from this set up that two points in image space correspond to a set of intersecting lines in the Hough space, where the point of intersection represents the line joining the two points in the image space. To get a better understanding, let us visualize the transformation of 4 points in image space into their representation in Hough space obtained by applying Hough transformation.
<div style="text-align:center"> <figcaption> Hough Transform</figcaption>  <img src="https://thekhblog.wordpress.com/wp-content/uploads/2017/02/hough_transform.jpg?w=554&h=277"></div> 


<br/>
All 4 lines in the Hough space as seen above intersect at a single point (m, c) which suggests that all the 4 points in the image space fall on a single line defined as y = m * x + c. Hence to identify lines in image space containing discreet points, we look for intersection points in the Hough space. Using a voting procedure carried out in the parameter space, object candidates (intersection points) are obtained as local maxima in a so-called accumulator (just a grid in the parameter space) that is explicitly constructed by the algorithm for computing the Hough transform. We can control the detection of lines by providing parameters that control the size of the accumulator and also the threshold value (minimum number of lines that should intersect in the Hough space so that the intersection point is considered while calculating local maxima). The output from this transformation function are the points in the Hough space that satisfy the conditions of our voting procedure. These points are then used to define lines in the image space, thus accomplishing the task of line detection. But since the slope (m) for a vertical line cannot be defined, the above transformation is limited in its capacity. This is overcome by defining a line using polar coordinates as rho = x * cos(theta) + y * sin(theta) and using the parameter space (rho vs. theta) instead of (m vs. c)! Now, instead of every point in image space being a line in Hough space (m vs. c), it is a sinusoidal curve (in rho vs. theta Hough space). Everything else about how intersection points in Hough space translate to lines in image space still holds true.

<div style="text-align:center"> <figcaption>Hough Lines augmented on an image</figcaption> <img src="https://thekhblog.wordpress.com/wp-content/uploads/2017/02/hough.gif"></div>